{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EdgeYolo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-09T11:15:35.052899Z",
     "iopub.status.busy": "2025-05-09T11:15:35.052703Z",
     "iopub.status.idle": "2025-05-09T11:19:15.706531Z",
     "shell.execute_reply": "2025-05-09T11:19:15.705610Z",
     "shell.execute_reply.started": "2025-05-09T11:15:35.052880Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'edgeyolo'...\n",
      "remote: Enumerating objects: 1906, done.\u001b[K\n",
      "remote: Counting objects: 100% (525/525), done.\u001b[K\n",
      "remote: Compressing objects: 100% (183/183), done.\u001b[K\n",
      "remote: Total 1906 (delta 483), reused 342 (delta 342), pack-reused 1381 (from 3)\u001b[K\n",
      "Receiving objects: 100% (1906/1906), 62.89 MiB | 30.23 MiB/s, done.\n",
      "Resolving deltas: 100% (1025/1025), done.\n",
      "/kaggle/working/edgeyolo\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu124)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.11.0.86)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
      "Collecting loguru (from -r requirements.txt (line 5))\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.0.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.9.0)\n",
      "Collecting thop (from -r requirements.txt (line 10))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.2.3)\n",
      "Requirement already satisfied: pathlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.0.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (11.1.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (3.7.5)\n",
      "Collecting mahotas (from -r requirements.txt (line 16))\n",
      "  Downloading mahotas-1.4.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (0.12.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (1.15.2)\n",
      "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (1.17.0)\n",
      "Collecting onnxsim (from -r requirements.txt (line 20))\n",
      "  Downloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 4)) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 4)) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 4)) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 4)) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 4)) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 4)) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 7)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 7)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 7)) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 12)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 12)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 12)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 15)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 15)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 15)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 15)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 15)) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 15)) (3.2.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->-r requirements.txt (line 19)) (3.20.3)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from onnxsim->-r requirements.txt (line 20)) (14.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 12)) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 4)) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 4)) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->-r requirements.txt (line 4)) (2024.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim->-r requirements.txt (line 20)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim->-r requirements.txt (line 20)) (2.19.1)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->-r requirements.txt (line 4)) (2024.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim->-r requirements.txt (line 20)) (0.1.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Downloading mahotas-1.4.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, loguru, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, onnxsim, mahotas\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed loguru-0.7.3 mahotas-1.4.18 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxsim-0.4.36 thop-0.1.1.post2209072238\n",
      "Collecting tensorrt\n",
      "  Downloading tensorrt-10.10.0.31.tar.gz (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting tensorrt_cu12==10.10.0.31 (from tensorrt)\n",
      "  Downloading tensorrt_cu12-10.10.0.31.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting tensorrt_cu12_libs==10.10.0.31 (from tensorrt_cu12==10.10.0.31->tensorrt)\n",
      "  Downloading tensorrt_cu12_libs-10.10.0.31.tar.gz (708 bytes)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting tensorrt_cu12_bindings==10.10.0.31 (from tensorrt_cu12==10.10.0.31->tensorrt)\n",
      "  Downloading tensorrt_cu12_bindings-10.10.0.31-cp311-none-manylinux_2_28_x86_64.whl.metadata (607 bytes)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.11/dist-packages (from tensorrt_cu12_libs==10.10.0.31->tensorrt_cu12==10.10.0.31->tensorrt) (12.4.127)\n",
      "Downloading tensorrt_cu12_bindings-10.10.0.31-cp311-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m960.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt_cu12, tensorrt_cu12_libs\n",
      "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tensorrt: filename=tensorrt-10.10.0.31-py2.py3-none-any.whl size=46633 sha256=a78bab3d7313746cfca44c67006856762a9dd2fc2cbb6997cad2c05e481838aa\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/04/6b/680eb64bea852e9183d35f8112879c19d02a37c4a7a3e9ab19\n",
      "  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.10.0.31-py2.py3-none-any.whl size=17482 sha256=523620934cfa28723ffc30731b709aed4fe381049665e1fc49b3a6e26996413e\n",
      "  Stored in directory: /root/.cache/pip/wheels/ef/6b/47/10dbe13e12085c48a6b521b5c62b7c4d27e9192fbc7069e27d\n",
      "  Building wheel for tensorrt_cu12_libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tensorrt_cu12_libs: filename=tensorrt_cu12_libs-10.10.0.31-py2.py3-none-manylinux_2_28_x86_64.whl size=3404991480 sha256=02a17ce9d84979d325a085e6492cfb71fae1039d4e7f55efe4de8e96d0410255\n",
      "  Stored in directory: /root/.cache/pip/wheels/ff/db/8e/03e6696471217bb7beca639a1f62de8c3b77dac3a53cafb068\n",
      "Successfully built tensorrt tensorrt_cu12 tensorrt_cu12_libs\n",
      "Installing collected packages: tensorrt_cu12_bindings, tensorrt_cu12_libs, tensorrt_cu12, tensorrt\n",
      "Successfully installed tensorrt-10.10.0.31 tensorrt_cu12-10.10.0.31 tensorrt_cu12_bindings-10.10.0.31 tensorrt_cu12_libs-10.10.0.31\n",
      "Cloning into 'torch2trt'...\n",
      "remote: Enumerating objects: 4452, done.\u001b[K\n",
      "remote: Counting objects: 100% (766/766), done.\u001b[K\n",
      "remote: Compressing objects: 100% (158/158), done.\u001b[K\n",
      "remote: Total 4452 (delta 650), reused 625 (delta 608), pack-reused 3686 (from 1)\u001b[K\n",
      "Receiving objects: 100% (4452/4452), 7.77 MiB | 25.90 MiB/s, done.\n",
      "Resolving deltas: 100% (2584/2584), done.\n",
      "/kaggle/working/edgeyolo/torch2trt\n",
      "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` and ``easy_install``.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "build/bdist.linux-x86_64/egg/torch2trt/dataset.py:61: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(self) > 0, 'Cannot create default flattener without input data.')\n",
      "/usr/local/lib/python3.11/dist-packages/torch2trt-0.5.0-py3.11.egg/torch2trt/dataset.py:61: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(self) > 0, 'Cannot create default flattener without input data.')\n",
      "/kaggle/working/edgeyolo\n",
      "assets\tdeployment\t  edgeyolo     LICENSE\tREADME_EN.md\t  torch2trt\n",
      "cpp\tdetect.py\t  evaluate.py  params\tREADME.md\t  train.py\n",
      "demo\tdocker_export.py  export.py    plot.py\trequirements.txt\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/LSH9832/edgeyolo.git\n",
    "%cd edgeyolo\n",
    "! pip install -r requirements.txt\n",
    "\n",
    "!pip install tensorrt\n",
    "\n",
    "! git clone https://github.com/NVIDIA-AI-IOT/torch2trt.git\n",
    "%cd torch2trt\n",
    "! python setup.py install\n",
    "%cd ..\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downlaod Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T11:22:07.595513Z",
     "iopub.status.busy": "2025-05-08T11:22:07.594857Z",
     "iopub.status.idle": "2025-05-08T11:22:42.158831Z",
     "shell.execute_reply": "2025-05-08T11:22:42.158033Z",
     "shell.execute_reply.started": "2025-05-08T11:22:07.595493Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=16MaG0L0M5M-ivtYKO7msq2ehTFrmGhzf\n",
      "To: /kaggle/working/edgeyolo/coco2017.tar.xz\n",
      "100%|██████████████████████████████████████| 76.9M/76.9M [00:01<00:00, 60.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "# https://drive.google.com/file/d/16MaG0L0M5M-ivtYKO7msq2ehTFrmGhzf/view?usp=sharing\n",
    "!gdown --id 16MaG0L0M5M-ivtYKO7msq2ehTFrmGhzf\n",
    "!tar -xJf /kaggle/working/edgeyolo/coco2017.tar.xz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Config: train_coco.yml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T11:20:33.835143Z",
     "iopub.status.busy": "2025-05-08T11:20:33.834606Z",
     "iopub.status.idle": "2025-05-08T11:20:33.957064Z",
     "shell.execute_reply": "2025-05-08T11:20:33.956164Z",
     "shell.execute_reply.started": "2025-05-08T11:20:33.835113Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# models & weights------------------------------------------------------------------------------------------------------\n",
      "model_cfg: \"params/model/edgeyolo_tiny.yaml\"         # model structure config file\n",
      "weights: \"output/train/edgeyolo_tiny_coco/last.pth\"  # contains model_cfg, set null or a no-exist filename if not use it\n",
      "use_cfg: false                                       # force using model_cfg instead of cfg in weights to build model\n",
      "\n",
      "# output----------------------------------------------------------------------------------------------------------------\n",
      "output_dir: \"output/train/edgeyolo_tiny_coco\"        # all train output file will save in this dir\n",
      "save_checkpoint_for_each_epoch: true                 # save models for each epoch (epoch_xxx.pth, not only best/last.pth)\n",
      "log_file: \"log.txt\"                                  # log file (in output_dir)\n",
      "\n",
      "# dataset & dataloader--------------------------------------------------------------------------------------------------\n",
      "dataset_cfg: \"params/dataset/coco.yaml\"              # dataset config\n",
      "batch_size_per_gpu: 8                                # batch size for each GPU\n",
      "loader_num_workers: 4                                # number data loader workers for each GPU\n",
      "num_threads: 1                                       # pytorch threads number for each GPU\n",
      "\n",
      "# device & data type----------------------------------------------------------------------------------------------------\n",
      "device: [0, 1, 2, 3]                                 # training device list\n",
      "fp16: false                                          # train with fp16 precision\n",
      "cudnn_benchmark: false                               # it's useful when multiscale_range is set zero\n",
      "\n",
      "# train hyper-params----------------------------------------------------------------------------------------------------\n",
      "optimizer: \"SGD\"                                     # or Adam\n",
      "max_epoch: 300                                       # or 400\n",
      "close_mosaic_epochs: 15                              # close data augmentation at last several epochs\n",
      "\n",
      "# learning rate---------------------------------------------------------------------------------------------------------\n",
      "lr_per_img: 0.00015625                               # total_lr = lr_per_img * batch_size_per_gpu * len(devices)\n",
      "warmup_epochs: 5                                     # warm-up epochs at the beginning of training\n",
      "warmup_lr_ratio: 0.0                                 # warm-up learning rate start from value warmup_lr_ratio * total_lr\n",
      "final_lr_ratio: 0.05                                 # final_lr_per_img = final_lr_ratio * lr_per_img\n",
      "\n",
      "# training & dataset augmentation---------------------------------------------------------------------------------------\n",
      "#      [cls_loss, conf_loss, iou_loss]\n",
      "loss_use: [\"bce\", \"bce\", \"giou\"]  # bce: BCE loss. bcf: Balanced Focal loss. hyb: HR loss, iou, c/g/s iou is available\n",
      "input_size: [640, 640]            # image input size for model\n",
      "multiscale_range: 5               # real_input_size = input_size + randint(-multiscale_range, multiscale_range) * 32\n",
      "weight_decay: 0.0005              # optimizer weight decay\n",
      "momentum: 0.9                     # optimizer momentum\n",
      "enhance_mosaic: false             # use enhanced mosaic method\n",
      "use_ema: true                     # use EMA method\n",
      "enable_mixup: true                # use mixup\n",
      "mixup_scale: [0.5, 1.5]           # mixup image scale\n",
      "mosaic_scale: [0.1, 2.0]          # mosaic image scale\n",
      "flip_prob: 0.5                    # flip image probability\n",
      "mosaic_prob: 1                    # mosaic probability\n",
      "mixup_prob: 1                     # mixup probability\n",
      "degrees: 10                       # maximum rotate degrees\n",
      "hsv_gain: [0.0138, 0.664, 0.464]  # hsv gain ratio\n",
      "\n",
      "# evaluate--------------------------------------------------------------------------------------------------------------\n",
      "eval_at_start: false              # evaluate loaded model before training\n",
      "val_conf_thres: 0.001             # confidence threshold when doing evaluation\n",
      "val_nms_thres: 0.65               # NMS IOU threshold when doing evaluation\n",
      "eval_only: false                  # do not train, run evaluation program only for all weights in output_dir\n",
      "obj_conf_enabled: true            # use object confidence when doing inference\n",
      "eval_interval: 1                  # evaluate interval epochs\n",
      "\n",
      "# show------------------------------------------------------------------------------------------------------------------\n",
      "print_interval: 100               # print result after every $print_interval iterations\n",
      "\n",
      "# others----------------------------------------------------------------------------------------------------------------\n",
      "load_optimizer_params: true       # load optimizer params when resume train, set false if there is an error.\n",
      "train_backbone: true              # set false if you only want to train yolo head\n",
      "train_start_layers: 51            # if not train_backbone, train from this layer, see params/models/edgeyolo.yaml\n",
      "force_start_epoch: -1             # set -1 to disable this option\n"
     ]
    }
   ],
   "source": [
    "!cat /kaggle/working/edgeyolo/params/train/train_coco.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T11:34:35.107070Z",
     "iopub.status.busy": "2025-05-08T11:34:35.106178Z",
     "iopub.status.idle": "2025-05-08T11:34:35.119440Z",
     "shell.execute_reply": "2025-05-08T11:34:35.118885Z",
     "shell.execute_reply.started": "2025-05-08T11:34:35.107040Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train config successfully overwritten.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "train_config = {\n",
    "    \"model_cfg\": \"params/model/edgeyolo_s.yaml\",\n",
    "    \"weights\": \"output/train/edgeyolo_s_coco/last.pth\",\n",
    "    \"use_cfg\": False,\n",
    "    \"output_dir\": \"output/train/edgeyolo_s_coco\",\n",
    "    \"save_checkpoint_for_each_epoch\": True,\n",
    "    \"log_file\": \"log.txt\",\n",
    "    \"dataset_cfg\": \"params/dataset/coco.yaml\",\n",
    "    \"batch_size_per_gpu\": 4,\n",
    "    \"loader_num_workers\": 2,\n",
    "    \"num_threads\": 1,\n",
    "    \"device\": [0, 1],\n",
    "    \"fp16\": False,\n",
    "    \"cudnn_benchmark\": False,\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"max_epoch\": 25,\n",
    "    \"close_mosaic_epochs\": 1,\n",
    "    \"lr_per_img\": 0.00015625,\n",
    "    \"warmup_epochs\": 5,\n",
    "    \"warmup_lr_ratio\": 0.0,\n",
    "    \"final_lr_ratio\": 0.05,\n",
    "    \"loss_use\": [\"bce\", \"bce\", \"giou\"],\n",
    "    \"input_size\": [640, 640],\n",
    "    \"multiscale_range\": 5,\n",
    "    \"weight_decay\": 0.0005,\n",
    "    \"momentum\": 0.9,\n",
    "    \"enhance_mosaic\": False,\n",
    "    \"use_ema\": True,\n",
    "    \"enable_mixup\": True,\n",
    "    \"mixup_scale\": [0.5, 1.5],\n",
    "    \"mosaic_scale\": [0.1, 2.0],\n",
    "    \"flip_prob\": 0.5,\n",
    "    \"mosaic_prob\": 1,\n",
    "    \"mixup_prob\": 1,\n",
    "    \"degrees\": 10,\n",
    "    \"hsv_gain\": [0.0138, 0.664, 0.464],\n",
    "    \"eval_at_start\": False,\n",
    "    \"val_conf_thres\": 0.001,\n",
    "    \"val_nms_thres\": 0.65,\n",
    "    \"eval_only\": False,\n",
    "    \"obj_conf_enabled\": True,\n",
    "    \"eval_interval\": 1,\n",
    "    \"print_interval\": 100,\n",
    "    \"load_optimizer_params\": True,\n",
    "    \"train_backbone\": True,\n",
    "    \"train_start_layers\": 51,\n",
    "    \"force_start_epoch\": -1,\n",
    "}\n",
    "\n",
    "yaml_path = \"/kaggle/working/edgeyolo/params/train/train_coco.yaml\"\n",
    "\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    yaml.dump(train_config, f, default_flow_style=False)\n",
    "\n",
    "print(\"✅ Train config successfully overwritten.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Config: coco.yml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!cat /kaggle/working/edgeyolo/params/dataset/coco.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T11:34:41.552071Z",
     "iopub.status.busy": "2025-05-08T11:34:41.551389Z",
     "iopub.status.idle": "2025-05-08T11:34:41.558515Z",
     "shell.execute_reply": "2025-05-08T11:34:41.557796Z",
     "shell.execute_reply.started": "2025-05-08T11:34:41.552048Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ YAML file successfully overwritten.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "yaml_path = \"/kaggle/working/edgeyolo/params/dataset/coco.yaml\"\n",
    "\n",
    "new_config = {\n",
    "    \"type\": \"coco\",\n",
    "    \"dataset_path\": \"coco2017\",\n",
    "    \"kwargs\": {\"suffix\": \"jpg\", \"use_cache\": True},\n",
    "    \"train\": {\n",
    "        \"image_dir\": \"train2017\",\n",
    "        \"label\": \"annotations/instances_train2017.json\",\n",
    "    },\n",
    "    \"val\": {\"image_dir\": \"val2017\", \"label\": \"annotations/instances_val2017.json\"},\n",
    "    \"test\": {\"test_dir\": \"test2017\"},\n",
    "    \"segmentation_enabled\": False,\n",
    "    \"names\": [\n",
    "        \"0\",\n",
    "        \"1\",\n",
    "        \"2\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    yaml.dump(new_config, f, default_flow_style=False)\n",
    "\n",
    "print(\"✅ YAML file successfully overwritten.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T11:34:45.135038Z",
     "iopub.status.busy": "2025-05-08T11:34:45.134406Z",
     "iopub.status.idle": "2025-05-08T12:31:58.123371Z",
     "shell.execute_reply": "2025-05-08T12:31:58.122546Z",
     "shell.execute_reply.started": "2025-05-08T11:34:45.135003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m20250508_113454\u001b[0m \u001b[36medgeyolo.models:97\u001b[0m - \u001b[1mno weight file found, setup models from cfg file /kaggle/working/edgeyolo/params/model/edgeyolo_s.yaml\u001b[0m\n",
      "\u001b[32m20250508_113454\u001b[0m \u001b[36medgeyolo.models.yolo:922\u001b[0m - \u001b[1mOverriding models.yaml nc=80 with nc=3\u001b[0m\n",
      "\u001b[32m20250508_113454\u001b[0m \u001b[36medgeyolo.models.yolo:922\u001b[0m - \u001b[1mOverriding models.yaml nc=80 with nc=3\u001b[0m\n",
      "/kaggle/working/edgeyolo/edgeyolo/train/trainer.py:104: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.params[\"fp16\"])\n",
      "add im\n",
      "add im\n",
      "add im\n",
      "add ia\n",
      "add ia\n",
      "add ia\n",
      "/kaggle/working/edgeyolo/edgeyolo/train/trainer.py:104: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.params[\"fp16\"])\n",
      "\u001b[32m20250508_113456\u001b[0m \u001b[36medgeyolo.train.trainer:334\u001b[0m - \u001b[1mparams:\n",
      "╒════════════════════════════════╤═══════════════════════════════════════╕\n",
      "│ Keywords                       │ Values                                │\n",
      "╞════════════════════════════════╪═══════════════════════════════════════╡\n",
      "│ batch_size_per_gpu             │ 4                                     │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ close_mosaic_epochs            │ 1                                     │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ cudnn_benchmark                │ False                                 │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ dataset_cfg                    │ params/dataset/coco.yaml              │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ degrees                        │ 10                                    │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ device                         │ [0, 1]                                │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ enable_mixup                   │ True                                  │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ enhance_mosaic                 │ False                                 │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ eval_at_start                  │ False                                 │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ eval_interval                  │ 1                                     │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ eval_only                      │ False                                 │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ final_lr_ratio                 │ 0.05                                  │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ flip_prob                      │ 0.5                                   │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ force_start_epoch              │ -1                                    │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ fp16                           │ False                                 │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ hsv_gain                       │ [0.0138, 0.664, 0.464]                │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ input_size                     │ [640, 640]                            │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ load_optimizer_params          │ True                                  │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ loader_num_workers             │ 2                                     │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ log_file                       │ log.txt                               │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ loss_use                       │ ['bce', 'bce', 'giou']                │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ lr_per_img                     │ 0.00015625                            │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ max_epoch                      │ 25                                    │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ mixup_prob                     │ 1                                     │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ mixup_scale                    │ [0.5, 1.5]                            │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ model_cfg                      │ params/model/edgeyolo_s.yaml          │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ momentum                       │ 0.9                                   │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ mosaic_prob                    │ 1                                     │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ mosaic_scale                   │ [0.1, 2.0]                            │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ multiscale_range               │ 5                                     │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ num_threads                    │ 1                                     │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ obj_conf_enabled               │ True                                  │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ optimizer                      │ SGD                                   │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ output_dir                     │ output/train/edgeyolo_s_coco          │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ print_interval                 │ 100                                   │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ save_checkpoint_for_each_epoch │ True                                  │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ train_backbone                 │ True                                  │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ train_start_layers             │ 51                                    │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ use_cfg                        │ False                                 │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ use_ema                        │ True                                  │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ val_conf_thres                 │ 0.001                                 │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ val_nms_thres                  │ 0.65                                  │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ warmup_epochs                  │ 5                                     │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ warmup_lr_ratio                │ 0.0                                   │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ weight_decay                   │ 0.0005                                │\n",
      "├────────────────────────────────┼───────────────────────────────────────┤\n",
      "│ weights                        │ output/train/edgeyolo_s_coco/last.pth │\n",
      "╘════════════════════════════════╧═══════════════════════════════════════╛\u001b[0m\n",
      "\u001b[32m20250508_113456\u001b[0m \u001b[36medgeyolo.train.trainer:335\u001b[0m - \u001b[1mnum classes: 3\u001b[0m\n",
      "\u001b[32m20250508_113457\u001b[0m \u001b[36medgeyolo.train.trainer:336\u001b[0m - \u001b[1mParams: 9.86M, Gflops: 45.31\u001b[0m\n",
      "\u001b[32m20250508_113457\u001b[0m \u001b[36medgeyolo.train.trainer:247\u001b[0m - \u001b[1mloading loss...\u001b[0m\n",
      "\u001b[32m20250508_113457\u001b[0m \u001b[36medgeyolo.train.trainer:223\u001b[0m - \u001b[1mloading optimizer...\u001b[0m\n",
      "add im\n",
      "add im\n",
      "add im\n",
      "add ia\n",
      "add ia\n",
      "add ia\n",
      "\u001b[32m20250508_113457\u001b[0m \u001b[36medgeyolo.train.optimizer:117\u001b[0m - \u001b[1mlength of PG0(BN weights):    163\u001b[0m\n",
      "\u001b[32m20250508_113457\u001b[0m \u001b[36medgeyolo.train.optimizer:118\u001b[0m - \u001b[1mlength of PG1(other weights): 142\u001b[0m\n",
      "\u001b[32m20250508_113457\u001b[0m \u001b[36medgeyolo.train.optimizer:119\u001b[0m - \u001b[1mlength of PG2(bias):          166\u001b[0m\n",
      "\u001b[32m20250508_113457\u001b[0m \u001b[36medgeyolo.train.trainer:116\u001b[0m - \u001b[1mloading dataset...\u001b[0m\n",
      "loading COCO dataset...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "max label number in one image: 3\n",
      "\u001b[32m20250508_113457\u001b[0m \u001b[36medgeyolo.train.trainer:168\u001b[0m - \u001b[1minit data prefetcher...\u001b[0m\n",
      "\u001b[32m20250508_113507\u001b[0m \u001b[36medgeyolo.train.trainer:178\u001b[0m - \u001b[1mprefetcher loaded!\u001b[0m\n",
      "\u001b[32m20250508_113507\u001b[0m \u001b[36medgeyolo.train.trainer:257\u001b[0m - \u001b[1minit learning rate scheduler...\u001b[0m\n",
      "\u001b[32m20250508_113507\u001b[0m \u001b[36medgeyolo.train.trainer:184\u001b[0m - \u001b[1mloading evaluator...\u001b[0m\n",
      "\u001b[32m20250508_113507\u001b[0m \u001b[36medgeyolo.train.trainer:219\u001b[0m - \u001b[1mevaluator loaded.\u001b[0m\n",
      "\u001b[32m20250508_113507\u001b[0m \u001b[36medgeyolo.train.trainer:355\u001b[0m - \u001b[1mTraining start...\u001b[0m\n",
      "\u001b[32m20250508_113507\u001b[0m \u001b[36medgeyolo.train.trainer:357\u001b[0m - \u001b[1m\n",
      "DistributedDataParallel(\n",
      "  (module): Model(\n",
      "    (model): Sequential(\n",
      "      (0): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(64, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(64, 80, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (4): Conv(\n",
      "        (conv): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (5): Conv(\n",
      "        (conv): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (6): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (7): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (8): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (9): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (10): Shortcut()\n",
      "      (11): Shortcut()\n",
      "      (12): Concat()\n",
      "      (13): Conv(\n",
      "        (conv): Conv2d(160, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (14): MP(\n",
      "        (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (15): Conv(\n",
      "        (conv): Conv2d(120, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (16): Conv(\n",
      "        (conv): Conv2d(120, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (17): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (18): Concat()\n",
      "      (19): Conv(\n",
      "        (conv): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (20): Conv(\n",
      "        (conv): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (21): Conv(\n",
      "        (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (22): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (23): Conv(\n",
      "        (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (24): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (25): Shortcut()\n",
      "      (26): Shortcut()\n",
      "      (27): Concat()\n",
      "      (28): Conv(\n",
      "        (conv): Conv2d(320, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (29): MP(\n",
      "        (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (30): Conv(\n",
      "        (conv): Conv2d(240, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (31): Conv(\n",
      "        (conv): Conv2d(240, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (32): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (33): Concat()\n",
      "      (34): Conv(\n",
      "        (conv): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (35): Conv(\n",
      "        (conv): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (36): Conv(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (37): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (38): Conv(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (39): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (40): Shortcut()\n",
      "      (41): Shortcut()\n",
      "      (42): Concat()\n",
      "      (43): Conv(\n",
      "        (conv): Conv2d(640, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (44): MP(\n",
      "        (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (45): Conv(\n",
      "        (conv): Conv2d(480, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (46): Conv(\n",
      "        (conv): Conv2d(480, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (47): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(320, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (48): Concat()\n",
      "      (49): Conv(\n",
      "        (conv): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (50): Conv(\n",
      "        (conv): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (51): Conv(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (52): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (53): Conv(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (54): Conv(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (55): Shortcut()\n",
      "      (56): Shortcut()\n",
      "      (57): Concat()\n",
      "      (58): Conv(\n",
      "        (conv): Conv2d(640, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (59): SPPCSPC(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(480, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(480, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (cv4): Conv(\n",
      "          (conv): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (m): ModuleList(\n",
      "          (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "          (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
      "          (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (cv5): Conv(\n",
      "          (conv): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (cv6): Conv(\n",
      "          (conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "        (cv7): Conv(\n",
      "          (conv): Conv2d(480, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (60): Conv(\n",
      "        (conv): Conv2d(240, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (61): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (62): Conv(\n",
      "        (conv): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (63): Concat()\n",
      "      (64): Conv(\n",
      "        (conv): Conv2d(240, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (65): Conv(\n",
      "        (conv): Conv2d(240, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (66): Conv(\n",
      "        (conv): Conv2d(120, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (67): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (68): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (69): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (70): Concat()\n",
      "      (71): Conv(\n",
      "        (conv): Conv2d(496, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (72): Conv(\n",
      "        (conv): Conv2d(120, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (73): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (74): Conv(\n",
      "        (conv): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (75): Concat()\n",
      "      (76): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (77): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (78): Conv(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (79): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (80): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (81): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (82): Concat()\n",
      "      (83): Conv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (84): MP(\n",
      "        (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (85): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (86): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (87): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (88): Concat()\n",
      "      (89): Conv(\n",
      "        (conv): Conv2d(248, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (90): Conv(\n",
      "        (conv): Conv2d(248, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (91): Conv(\n",
      "        (conv): Conv2d(120, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (92): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (93): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (94): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (95): Concat()\n",
      "      (96): Conv(\n",
      "        (conv): Conv2d(496, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (97): MP(\n",
      "        (m): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (98): Conv(\n",
      "        (conv): Conv2d(120, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (99): Conv(\n",
      "        (conv): Conv2d(120, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (100): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(120, 120, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (101): Concat()\n",
      "      (102): Conv(\n",
      "        (conv): Conv2d(480, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (103): Conv(\n",
      "        (conv): Conv2d(480, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (104): Conv(\n",
      "        (conv): Conv2d(240, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "        (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (105): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(120, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (106): Conv(\n",
      "        (conv): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n",
      "        (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (107): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_identity): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(120, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (108): Concat()\n",
      "      (109): Conv(\n",
      "        (conv): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (110): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(64, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(64, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (111): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(120, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(120, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (112): RepConv(\n",
      "        (act): SiLU()\n",
      "        (rbr_dense): Sequential(\n",
      "          (0): Conv2d(240, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (0): Conv2d(240, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (113): YOLOXDetect(\n",
      "        (stems): ModuleList(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(120, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(240, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "          (2): Conv(\n",
      "            (conv): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (cls_convs): ModuleList(\n",
      "          (0-2): 3 x RepConv(\n",
      "            (act): SiLU()\n",
      "            (rbr_identity): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): Sequential(\n",
      "              (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): Sequential(\n",
      "              (0): Conv2d(120, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (reg_convs): ModuleList(\n",
      "          (0-2): 3 x RepConv(\n",
      "            (act): SiLU()\n",
      "            (rbr_identity): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): Sequential(\n",
      "              (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): Sequential(\n",
      "              (0): Conv2d(120, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (cls_preds): ModuleList(\n",
      "          (0-2): 3 x Conv2d(120, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (reg_preds): ModuleList(\n",
      "          (0-2): 3 x Conv2d(120, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (obj_preds): ModuleList(\n",
      "          (0-2): 3 x Conv2d(120, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (ia): ModuleList(\n",
      "          (0-2): 3 x ImplicitA()\n",
      "        )\n",
      "        (im): ModuleList(\n",
      "          (0-2): 3 x ImplicitM()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\u001b[0m\n",
      "\u001b[32m20250508_113507\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 1 \u001b[0m\n",
      "/kaggle/working/edgeyolo/edgeyolo/train/trainer.py:401: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.params[\"fp16\"]):\n",
      "/kaggle/working/edgeyolo/edgeyolo/train/trainer.py:401: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.params[\"fp16\"]):\n",
      "/usr/local/lib/python3.11/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/kaggle/working/edgeyolo/edgeyolo/utils/boxes.py:119: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /root/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)\n",
      "  area_a = torch.prod(bboxes_a[:, 2:], 1)\n",
      "/kaggle/working/edgeyolo/edgeyolo/train/loss.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/kaggle/working/edgeyolo/edgeyolo/train/loss.py:532: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "\u001b[32m20250508_113556\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:1/25 iter:100/248 mem:6121MB t_iter:0.42 lr:8.130e-06 loss:{total:22.98 iou:5.37 conf:15.41 cls:2.20} ETA:0:49:14\u001b[0m\n",
      "\u001b[32m20250508_113642\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:1/25 iter:200/248 mem:6121MB t_iter:0.34 lr:3.252e-05 loss:{total:11.40 iou:4.36 conf:5.34 cls:1.70} ETA:0:47:16\u001b[0m\n",
      "/kaggle/working/edgeyolo/edgeyolo/utils/allreduce_norm.py:39: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = torch.ByteStorage.from_buffer(pickle.dumps(pyobj))\n",
      "\u001b[32m20250508_113705\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_113705\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_01.pth\u001b[0m\n",
      "/kaggle/working/edgeyolo/edgeyolo/utils/allreduce_norm.py:39: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = torch.ByteStorage.from_buffer(pickle.dumps(pyobj))\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.86it/s]\n",
      "/kaggle/working/edgeyolo/edgeyolo/train/val/coco_evaluator.py:144: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  statistics = torch.cuda.FloatTensor([inference_time, nms_time, n_samples])\n",
      "\u001b[32m20250508_113719\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "/kaggle/working/edgeyolo/edgeyolo/train/val/coco_evaluator.py:144: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  statistics = torch.cuda.FloatTensor([inference_time, nms_time, n_samples])\n",
      "\u001b[32m20250508_113719\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_113719\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_113719\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.49s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.13s).\n",
      "\u001b[32m20250508_113720\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 27.29 ms, Average NMS time: 1.84 ms, Average inference time: 29.13 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_113720\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_113721\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_113721\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_01.pth\u001b[0m\n",
      "\u001b[32m20250508_113721\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 2 \u001b[0m\n",
      "\u001b[32m20250508_113811\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:2/25 iter:100/248 mem:6121MB t_iter:0.43 lr:9.845e-05 loss:{total:8.54 iou:3.38 conf:3.94 cls:1.22} ETA:0:51:25\u001b[0m\n",
      "\u001b[32m20250508_113858\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:2/25 iter:200/248 mem:6121MB t_iter:0.59 lr:1.632e-04 loss:{total:9.79 iou:3.31 conf:5.51 cls:0.97} ETA:0:49:16\u001b[0m\n",
      "\u001b[32m20250508_113922\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_113923\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_02.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.83it/s]\n",
      "\u001b[32m20250508_113936\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_113937\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_113937\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_113937\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.17s).\n",
      "\u001b[32m20250508_113938\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.21 ms, Average NMS time: 1.13 ms, Average inference time: 26.34 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.047\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.111\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_113938\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_113938\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_113939\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_02.pth\u001b[0m\n",
      "\u001b[32m20250508_113939\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 3 \u001b[0m\n",
      "\u001b[32m20250508_114030\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:3/25 iter:100/248 mem:6121MB t_iter:0.42 lr:2.888e-04 loss:{total:7.75 iou:2.52 conf:4.16 cls:1.08} ETA:0:50:31\u001b[0m\n",
      "\u001b[32m20250508_114120\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:3/25 iter:200/248 mem:6121MB t_iter:0.71 lr:3.938e-04 loss:{total:9.07 iou:2.73 conf:5.26 cls:1.08} ETA:0:49:06\u001b[0m\n",
      "\u001b[32m20250508_114142\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_114143\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_03.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.79it/s]\n",
      "\u001b[32m20250508_114157\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_114157\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_114157\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_114157\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.44s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      "\u001b[32m20250508_114158\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.28 ms, Average NMS time: 1.09 ms, Average inference time: 26.37 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.185\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_114158\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_114158\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_114158\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_03.pth\u001b[0m\n",
      "\u001b[32m20250508_114158\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 4 \u001b[0m\n",
      "\u001b[32m20250508_114245\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:4/25 iter:100/248 mem:6121MB t_iter:0.62 lr:5.791e-04 loss:{total:8.48 iou:2.60 conf:4.68 cls:1.20} ETA:0:48:26\u001b[0m\n",
      "\u001b[32m20250508_114333\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:4/25 iter:200/248 mem:6121MB t_iter:0.40 lr:7.245e-04 loss:{total:8.39 iou:2.43 conf:4.96 cls:1.00} ETA:0:46:56\u001b[0m\n",
      "\u001b[32m20250508_114356\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_114357\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_04.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.82it/s]\n",
      "\u001b[32m20250508_114411\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_114412\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_114412\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_114412\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.70s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      "\u001b[32m20250508_114413\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.06 ms, Average NMS time: 1.07 ms, Average inference time: 26.14 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.193\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_114413\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_114413\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_114413\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_04.pth\u001b[0m\n",
      "\u001b[32m20250508_114413\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 5 \u001b[0m\n",
      "\u001b[32m20250508_114501\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:5/25 iter:100/248 mem:6121MB t_iter:0.55 lr:9.694e-04 loss:{total:8.23 iou:2.67 conf:4.44 cls:1.12} ETA:0:46:17\u001b[0m\n",
      "\u001b[32m20250508_114549\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:5/25 iter:200/248 mem:6121MB t_iter:0.50 lr:1.155e-03 loss:{total:8.03 iou:2.61 conf:4.19 cls:1.23} ETA:0:44:55\u001b[0m\n",
      "\u001b[32m20250508_114613\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_114614\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_05.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.87it/s]\n",
      "\u001b[32m20250508_114627\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_114628\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_114628\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_114628\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.45s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.13s).\n",
      "\u001b[32m20250508_114628\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.18 ms, Average NMS time: 1.12 ms, Average inference time: 26.30 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.160\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_114629\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_114629\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_05.pth\u001b[0m\n",
      "\u001b[32m20250508_114629\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 6 \u001b[0m\n",
      "\u001b[32m20250508_114717\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:6/25 iter:100/248 mem:6121MB t_iter:0.34 lr:1.249e-03 loss:{total:8.49 iou:2.70 conf:4.65 cls:1.13} ETA:0:44:08\u001b[0m\n",
      "\u001b[32m20250508_114805\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:6/25 iter:200/248 mem:6121MB t_iter:0.35 lr:1.245e-03 loss:{total:7.25 iou:2.04 conf:4.25 cls:0.96} ETA:0:42:51\u001b[0m\n",
      "\u001b[32m20250508_114829\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_114829\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_06.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.83it/s]\n",
      "\u001b[32m20250508_114843\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_114843\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_114843\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_114843\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.46s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.13s).\n",
      "\u001b[32m20250508_114844\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.28 ms, Average NMS time: 1.14 ms, Average inference time: 26.42 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_114844\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_114845\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_114845\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_06.pth\u001b[0m\n",
      "\u001b[32m20250508_114845\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 7 \u001b[0m\n",
      "\u001b[32m20250508_114936\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:7/25 iter:100/248 mem:6121MB t_iter:0.68 lr:1.234e-03 loss:{total:7.65 iou:2.28 conf:4.32 cls:1.05} ETA:0:42:02\u001b[0m\n",
      "\u001b[32m20250508_115024\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:7/25 iter:200/248 mem:6121MB t_iter:0.47 lr:1.224e-03 loss:{total:6.96 iou:2.14 conf:3.81 cls:1.00} ETA:0:40:50\u001b[0m\n",
      "\u001b[32m20250508_115048\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_115048\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_07.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:14<00:00,  1.78it/s]\n",
      "\u001b[32m20250508_115102\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_115102\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_115102\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_115102\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.39s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      "\u001b[32m20250508_115103\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.15 ms, Average NMS time: 1.10 ms, Average inference time: 26.25 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_115103\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_115103\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_115104\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_07.pth\u001b[0m\n",
      "\u001b[32m20250508_115104\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 8 \u001b[0m\n",
      "\u001b[32m20250508_115153\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:8/25 iter:100/248 mem:6121MB t_iter:0.42 lr:1.204e-03 loss:{total:7.39 iou:1.99 conf:4.41 cls:0.99} ETA:0:39:49\u001b[0m\n",
      "\u001b[32m20250508_115241\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:8/25 iter:200/248 mem:6121MB t_iter:0.55 lr:1.187e-03 loss:{total:7.52 iou:2.23 conf:4.45 cls:0.84} ETA:0:38:40\u001b[0m\n",
      "\u001b[32m20250508_115306\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_115306\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_08.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.86it/s]\n",
      "\u001b[32m20250508_115319\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_115320\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_115320\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_115320\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.56s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "\u001b[32m20250508_115321\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.16 ms, Average NMS time: 1.06 ms, Average inference time: 26.22 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.287\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.394\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_115321\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_115321\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_115321\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_08.pth\u001b[0m\n",
      "\u001b[32m20250508_115321\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 9 \u001b[0m\n",
      "\u001b[32m20250508_115411\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:9/25 iter:100/248 mem:6121MB t_iter:0.36 lr:1.158e-03 loss:{total:7.79 iou:2.52 conf:4.29 cls:0.97} ETA:0:37:39\u001b[0m\n",
      "\u001b[32m20250508_115458\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:9/25 iter:200/248 mem:6121MB t_iter:0.34 lr:1.136e-03 loss:{total:5.37 iou:1.80 conf:2.60 cls:0.97} ETA:0:36:30\u001b[0m\n",
      "\u001b[32m20250508_115523\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_115523\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_09.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.86it/s]\n",
      "\u001b[32m20250508_115536\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_115537\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_115537\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_115537\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.62s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.17s).\n",
      "\u001b[32m20250508_115538\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.33 ms, Average NMS time: 1.17 ms, Average inference time: 26.50 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.326\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.101\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.114\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.426\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_115538\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_115538\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_09.pth\u001b[0m\n",
      "\u001b[32m20250508_115538\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 10 \u001b[0m\n",
      "\u001b[32m20250508_115628\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:10/25 iter:100/248 mem:6121MB t_iter:0.58 lr:1.099e-03 loss:{total:7.34 iou:2.10 conf:4.28 cls:0.95} ETA:0:35:23\u001b[0m\n",
      "\u001b[32m20250508_115716\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:10/25 iter:200/248 mem:6121MB t_iter:0.39 lr:1.072e-03 loss:{total:6.09 iou:1.68 conf:3.33 cls:1.08} ETA:0:34:19\u001b[0m\n",
      "\u001b[32m20250508_115741\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_115741\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_10.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.83it/s]\n",
      "\u001b[32m20250508_115755\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_115755\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_115755\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_115755\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.55s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "\u001b[32m20250508_115756\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.48 ms, Average NMS time: 1.19 ms, Average inference time: 26.67 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.333\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.152\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.279\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.453\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_115756\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_115757\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_115757\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_10.pth\u001b[0m\n",
      "\u001b[32m20250508_115757\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 11 \u001b[0m\n",
      "\u001b[32m20250508_115846\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:11/25 iter:100/248 mem:6121MB t_iter:0.58 lr:1.028e-03 loss:{total:6.25 iou:1.83 conf:3.49 cls:0.92} ETA:0:33:10\u001b[0m\n",
      "\u001b[32m20250508_115934\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:11/25 iter:200/248 mem:6121MB t_iter:0.54 lr:9.967e-04 loss:{total:6.49 iou:1.85 conf:3.51 cls:1.13} ETA:0:32:06\u001b[0m\n",
      "\u001b[32m20250508_115958\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_115958\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_11.pth\u001b[0m\n",
      "  0%|                                                                        | 0/25 [00:00<?, ?it/s]\u001b[32m20250508_120154\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:12/25 iter:200/248 mem:6121MB t_iter:0.42 lr:9.120e-04 loss:{total:6.10 iou:2.07 conf:3.23 cls:0.81} ETA:0:29:55\u001b[0m\n",
      "\u001b[32m20250508_120217\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_120217\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_12.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.91it/s]\n",
      "\u001b[32m20250508_120230\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_120231\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_120231\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_120231\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.50s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      "\u001b[32m20250508_120231\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.26 ms, Average NMS time: 0.95 ms, Average inference time: 26.22 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.516\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.471\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.538\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.556\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_120232\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_120232\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_120232\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_12.pth\u001b[0m\n",
      "\u001b[32m20250508_120232\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 13 \u001b[0m\n",
      "\u001b[32m20250508_120322\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:13/25 iter:100/248 mem:6121MB t_iter:0.32 lr:8.580e-04 loss:{total:4.94 iou:1.63 conf:2.53 cls:0.78} ETA:0:28:41\u001b[0m\n",
      "\u001b[32m20250508_120408\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:13/25 iter:200/248 mem:6121MB t_iter:0.39 lr:8.203e-04 loss:{total:5.33 iou:1.64 conf:2.87 cls:0.82} ETA:0:27:37\u001b[0m\n",
      "\u001b[32m20250508_120432\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_120432\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_13.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.87it/s]\n",
      "\u001b[32m20250508_120445\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_120445\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_120445\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_120445\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.58s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      "\u001b[32m20250508_120446\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 26.13 ms, Average NMS time: 1.06 ms, Average inference time: 27.19 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.585\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.236\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.456\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.489\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_120447\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_120447\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_120447\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_13.pth\u001b[0m\n",
      "\u001b[32m20250508_120447\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 14 \u001b[0m\n",
      "\u001b[32m20250508_120538\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:14/25 iter:100/248 mem:6121MB t_iter:0.34 lr:7.633e-04 loss:{total:5.04 iou:1.71 conf:2.57 cls:0.75} ETA:0:26:23\u001b[0m\n",
      "\u001b[32m20250508_120623\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:14/25 iter:200/248 mem:6121MB t_iter:0.34 lr:7.242e-04 loss:{total:4.75 iou:1.76 conf:2.18 cls:0.81} ETA:0:25:21\u001b[0m\n",
      "\u001b[32m20250508_120647\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_120648\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_14.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.87it/s]\n",
      "\u001b[32m20250508_120701\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_120701\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_120701\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_120701\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.35s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n",
      "\u001b[32m20250508_120702\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.43 ms, Average NMS time: 1.22 ms, Average inference time: 26.65 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.678\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.522\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.554\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.568\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_120702\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_120702\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_120703\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_14.pth\u001b[0m\n",
      "\u001b[32m20250508_120703\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 15 \u001b[0m\n",
      "\u001b[32m20250508_120753\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:15/25 iter:100/248 mem:6121MB t_iter:0.62 lr:6.658e-04 loss:{total:5.17 iou:1.68 conf:2.71 cls:0.77} ETA:0:24:06\u001b[0m\n",
      "\u001b[32m20250508_120843\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:15/25 iter:200/248 mem:6121MB t_iter:0.61 lr:6.262e-04 loss:{total:6.92 iou:1.83 conf:4.13 cls:0.96} ETA:0:23:07\u001b[0m\n",
      "\u001b[32m20250508_120906\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_120906\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_15.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.87it/s]\n",
      "\u001b[32m20250508_120920\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_120920\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_120920\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_120920\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.31s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      "\u001b[32m20250508_120920\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.33 ms, Average NMS time: 1.09 ms, Average inference time: 26.42 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.744\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.385\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.424\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.527\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.574\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_120921\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_120921\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_120921\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_15.pth\u001b[0m\n",
      "\u001b[32m20250508_120921\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 16 \u001b[0m\n",
      "\u001b[32m20250508_121009\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:16/25 iter:100/248 mem:6121MB t_iter:0.31 lr:5.679e-04 loss:{total:6.02 iou:1.91 conf:3.24 cls:0.87} ETA:0:21:49\u001b[0m\n",
      "\u001b[32m20250508_121100\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:16/25 iter:200/248 mem:6121MB t_iter:0.33 lr:5.290e-04 loss:{total:5.52 iou:1.83 conf:2.55 cls:1.14} ETA:0:20:52\u001b[0m\n",
      "\u001b[32m20250508_121124\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_121124\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_16.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.88it/s]\n",
      "\u001b[32m20250508_121138\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_121138\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_121138\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_121138\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.32s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      "\u001b[32m20250508_121138\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.56 ms, Average NMS time: 1.15 ms, Average inference time: 26.71 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.678\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.267\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.433\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.564\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.585\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_121138\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_121139\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_16.pth\u001b[0m\n",
      "\u001b[32m20250508_121139\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 17 \u001b[0m\n",
      "\u001b[32m20250508_121227\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:17/25 iter:100/248 mem:6121MB t_iter:0.33 lr:4.725e-04 loss:{total:5.15 iou:1.73 conf:2.51 cls:0.91} ETA:0:19:34\u001b[0m\n",
      "\u001b[32m20250508_121316\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:17/25 iter:200/248 mem:6121MB t_iter:0.32 lr:4.353e-04 loss:{total:5.05 iou:1.69 conf:2.53 cls:0.83} ETA:0:18:35\u001b[0m\n",
      "\u001b[32m20250508_121340\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_121340\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_17.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:12<00:00,  1.93it/s]\n",
      "\u001b[32m20250508_121353\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_121354\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_121354\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_121354\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.32s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      "\u001b[32m20250508_121354\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.57 ms, Average NMS time: 1.10 ms, Average inference time: 26.66 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.421\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.800\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.432\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.489\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.586\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.610\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_121355\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_121355\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_121355\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_17.pth\u001b[0m\n",
      "\u001b[32m20250508_121355\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 18 \u001b[0m\n",
      "\u001b[32m20250508_121444\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:18/25 iter:100/248 mem:6121MB t_iter:0.47 lr:3.820e-04 loss:{total:5.40 iou:1.93 conf:2.65 cls:0.82} ETA:0:17:17\u001b[0m\n",
      "\u001b[32m20250508_121531\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:18/25 iter:200/248 mem:6121MB t_iter:0.46 lr:3.476e-04 loss:{total:4.49 iou:1.54 conf:2.23 cls:0.72} ETA:0:16:19\u001b[0m\n",
      "\u001b[32m20250508_121556\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_121556\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_18.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.90it/s]\n",
      "\u001b[32m20250508_121610\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_121610\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_121610\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_121610\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n",
      "\u001b[32m20250508_121610\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.59 ms, Average NMS time: 1.20 ms, Average inference time: 26.79 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.738\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.595\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.450\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.635\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_121611\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_121611\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_18.pth\u001b[0m\n",
      "\u001b[32m20250508_121611\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 19 \u001b[0m\n",
      "\u001b[32m20250508_121659\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:19/25 iter:100/248 mem:6121MB t_iter:0.34 lr:2.991e-04 loss:{total:6.85 iou:1.98 conf:3.89 cls:0.98} ETA:0:15:00\u001b[0m\n",
      "\u001b[32m20250508_121748\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:19/25 iter:200/248 mem:6121MB t_iter:0.33 lr:2.683e-04 loss:{total:4.16 iou:1.50 conf:1.90 cls:0.76} ETA:0:14:03\u001b[0m\n",
      "\u001b[32m20250508_121813\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_121813\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_19.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.88it/s]\n",
      "\u001b[32m20250508_121827\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_121827\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_121827\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_121827\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.32s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n",
      "\u001b[32m20250508_121828\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.51 ms, Average NMS time: 1.25 ms, Average inference time: 26.76 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.817\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.295\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.491\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.589\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.507\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.597\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_121828\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_121828\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_19.pth\u001b[0m\n",
      "\u001b[32m20250508_121828\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 20 \u001b[0m\n",
      "\u001b[32m20250508_121915\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:20/25 iter:100/248 mem:6121MB t_iter:0.36 lr:2.259e-04 loss:{total:5.19 iou:1.80 conf:2.61 cls:0.77} ETA:0:12:43\u001b[0m\n",
      "\u001b[32m20250508_122003\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:20/25 iter:200/248 mem:6121MB t_iter:0.62 lr:1.996e-04 loss:{total:5.30 iou:1.64 conf:2.81 cls:0.85} ETA:0:11:46\u001b[0m\n",
      "\u001b[32m20250508_122028\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_122028\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_20.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.90it/s]\n",
      "\u001b[32m20250508_122041\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_122041\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_122041\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_122041\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.30s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      "\u001b[32m20250508_122042\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.50 ms, Average NMS time: 1.04 ms, Average inference time: 26.54 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.819\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.439\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.302\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.503\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.590\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_122042\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_122042\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_122042\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_20.pth\u001b[0m\n",
      "\u001b[32m20250508_122042\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 21 \u001b[0m\n",
      "\u001b[32m20250508_122131\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:21/25 iter:100/248 mem:6121MB t_iter:0.51 lr:1.644e-04 loss:{total:4.71 iou:1.40 conf:2.57 cls:0.73} ETA:0:10:27\u001b[0m\n",
      "\u001b[32m20250508_122222\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:21/25 iter:200/248 mem:6121MB t_iter:0.62 lr:1.434e-04 loss:{total:4.32 iou:1.34 conf:2.30 cls:0.67} ETA:0:09:31\u001b[0m\n",
      "\u001b[32m20250508_122245\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_122245\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_21.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:12<00:00,  1.94it/s]\n",
      "\u001b[32m20250508_122258\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_122259\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_122259\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_122259\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.27s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      "\u001b[32m20250508_122259\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.44 ms, Average NMS time: 1.19 ms, Average inference time: 26.64 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.836\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.475\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.491\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.551\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.620\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.629\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.493\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.640\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_122259\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_122300\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_122300\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_21.pth\u001b[0m\n",
      "\u001b[32m20250508_122300\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 22 \u001b[0m\n",
      "\u001b[32m20250508_122347\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:22/25 iter:100/248 mem:6121MB t_iter:0.45 lr:1.164e-04 loss:{total:4.82 iou:1.44 conf:2.52 cls:0.87} ETA:0:08:10\u001b[0m\n",
      "\u001b[32m20250508_122434\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:22/25 iter:200/248 mem:6121MB t_iter:0.39 lr:1.011e-04 loss:{total:5.65 iou:2.04 conf:2.72 cls:0.89} ETA:0:07:14\u001b[0m\n",
      "\u001b[32m20250508_122459\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_122459\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_22.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.88it/s]\n",
      "\u001b[32m20250508_122513\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_122513\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_122513\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_122513\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.28s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      "\u001b[32m20250508_122513\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.38 ms, Average NMS time: 1.05 ms, Average inference time: 26.43 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.814\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.523\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.609\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.564\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_122514\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_122514\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_22.pth\u001b[0m\n",
      "\u001b[32m20250508_122514\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 23 \u001b[0m\n",
      "\u001b[32m20250508_122602\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:23/25 iter:100/248 mem:6121MB t_iter:0.63 lr:8.307e-05 loss:{total:5.08 iou:1.78 conf:2.51 cls:0.79} ETA:0:05:54\u001b[0m\n",
      "\u001b[32m20250508_122649\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:23/25 iter:200/248 mem:6121MB t_iter:0.45 lr:7.402e-05 loss:{total:4.37 iou:1.36 conf:2.29 cls:0.72} ETA:0:04:58\u001b[0m\n",
      "\u001b[32m20250508_122713\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_122714\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_23.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.85it/s]\n",
      "\u001b[32m20250508_122727\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_122727\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_122727\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_122727\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.27s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      "\u001b[32m20250508_122728\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.55 ms, Average NMS time: 1.12 ms, Average inference time: 26.67 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.823\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.454\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.455\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.506\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.632\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.550\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.640\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_122728\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_122728\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_23.pth\u001b[0m\n",
      "\u001b[32m20250508_122728\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 24 \u001b[0m\n",
      "\u001b[32m20250508_122817\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:24/25 iter:100/248 mem:6121MB t_iter:0.52 lr:6.539e-05 loss:{total:4.56 iou:1.30 conf:2.39 cls:0.87} ETA:0:03:37\u001b[0m\n",
      "\u001b[32m20250508_122907\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:24/25 iter:200/248 mem:6121MB t_iter:0.50 lr:6.280e-05 loss:{total:4.47 iou:1.12 conf:2.70 cls:0.65} ETA:0:02:42\u001b[0m\n",
      "\u001b[32m20250508_122930\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_122930\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_24.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:13<00:00,  1.91it/s]\n",
      "\u001b[32m20250508_122943\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_122943\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_122943\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_122943\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.26s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      "\u001b[32m20250508_122944\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.53 ms, Average NMS time: 1.22 ms, Average inference time: 26.75 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.844\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.530\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.571\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.635\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.653\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_122944\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_122944\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_122945\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_24.pth\u001b[0m\n",
      "\u001b[32m20250508_122945\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last_augmentation_epoch.pth\u001b[0m\n",
      "\u001b[32m20250508_122945\u001b[0m \u001b[36medgeyolo.train.trainer:380\u001b[0m - \u001b[1mStart Train Epoch 25 (No mosaic aug, L1 loss enabled)\u001b[0m\n",
      "\u001b[32m20250508_123034\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:25/25 iter:100/248 mem:6121MB t_iter:0.48 lr:6.250e-05 loss:{total:4.25 iou:0.99 l1:1.17 conf:1.48 cls:0.61} ETA:0:01:21\u001b[0m\n",
      "\u001b[32m20250508_123118\u001b[0m \u001b[36medgeyolo.train.trainer:458\u001b[0m - \u001b[1mepoch:25/25 iter:200/248 mem:6121MB t_iter:0.58 lr:6.250e-05 loss:{total:3.81 iou:1.07 l1:1.15 conf:1.06 cls:0.53} ETA:0:00:26\u001b[0m\n",
      "\u001b[32m20250508_123141\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_123141\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_25.pth\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████| 25/25 [00:12<00:00,  1.94it/s]\n",
      "\u001b[32m20250508_123154\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:149\u001b[0m - \u001b[1mRank0: gathering data from subprocess...\u001b[0m\n",
      "\u001b[32m20250508_123154\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:154\u001b[0m - \u001b[1mdata gathered.\u001b[0m\n",
      "\u001b[32m20250508_123154\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:208\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m20250508_123154\u001b[0m \u001b[36medgeyolo.train.val.coco_evaluator:241\u001b[0m - \u001b[1mUse standard COCO evaluator.\u001b[0m\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.26s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      "\u001b[32m20250508_123155\u001b[0m \u001b[36medgeyolo.train.trainer:524\u001b[0m - \u001b[1m\n",
      "Average forward time: 25.44 ms, Average NMS time: 0.89 ms, Average inference time: 26.33 ms\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.842\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.562\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.558\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.504\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.565\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.640\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.641\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\n",
      "\u001b[0m\n",
      "\u001b[32m20250508_123155\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/last.pth\u001b[0m\n",
      "\u001b[32m20250508_123155\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "\u001b[32m20250508_123156\u001b[0m \u001b[36medgeyolo.models:146\u001b[0m - \u001b[1mweight file saved to output/train/edgeyolo_s_coco/epoch_25.pth\u001b[0m\n",
      "\u001b[32m20250508_123156\u001b[0m \u001b[36medgeyolo.train.trainer:491\u001b[0m - \u001b[1mTraining Finished.\u001b[0m\n",
      "\u001b[32m20250508_123156\u001b[0m \u001b[36medgeyolo.train.trainer:492\u001b[0m - \u001b[1mTime Spent: 0:56:48.324853\u001b[0m\n",
      "\u001b[32m20250508_123156\u001b[0m \u001b[36medgeyolo.train.trainer:493\u001b[0m - \u001b[1mbest mAP_50:95 = 0.50207 at epoch 25.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --cfg ./params/train/train_coco.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:32:23.489541Z",
     "iopub.status.busy": "2025-05-08T12:32:23.489204Z",
     "iopub.status.idle": "2025-05-08T12:32:28.987221Z",
     "shell.execute_reply": "2025-05-08T12:32:28.986286Z",
     "shell.execute_reply.started": "2025-05-08T12:32:23.489509Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-08 12:32:28.090\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36medgeyolo.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m107\u001b[0m - \u001b[31m\u001b[1mno weights and cfg found!\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/kaggle/working/edgeyolo/evaluate.py\", line 211, in <module>\n",
      "    launch(\n",
      "  File \"/kaggle/working/edgeyolo/evaluate.py\", line 204, in launch\n",
      "    eval_single(params=params)\n",
      "  File \"/kaggle/working/edgeyolo/evaluate.py\", line 148, in eval_single\n",
      "    ey = EdgeYOLO(weights=params.get(\"weights\"))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/kaggle/working/edgeyolo/edgeyolo/models/__init__.py\", line 108, in __init__\n",
      "    assert False\n",
      "           ^^^^^\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "!python evaluate.py --weights output/train/edgeyolo_tiny_coco/best.pth --dataset params/dataset/coco.yaml --batch 16 --device 0 --input-size 640 640 --save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Config: plot.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:32:28.988650Z",
     "iopub.status.busy": "2025-05-08T12:32:28.988397Z",
     "iopub.status.idle": "2025-05-08T12:32:28.994386Z",
     "shell.execute_reply": "2025-05-08T12:32:28.993791Z",
     "shell.execute_reply.started": "2025-05-08T12:32:28.988627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path = \"/kaggle/working/edgeyolo/plot.py\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    for line in lines:\n",
    "        if \"matplotlib.use(\" in line:\n",
    "            f.write(\"matplotlib.use('Agg')\\n\")\n",
    "        else:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:32:28.995203Z",
     "iopub.status.busy": "2025-05-08T12:32:28.995010Z",
     "iopub.status.idle": "2025-05-08T12:32:34.447910Z",
     "shell.execute_reply": "2025-05-08T12:32:34.447152Z",
     "shell.execute_reply.started": "2025-05-08T12:32:28.995189Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-08 12:32:33.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36medgeyolo.utils.plot_fig\u001b[0m:\u001b[36mplot_all\u001b[0m:\u001b[36m132\u001b[0m - \u001b[1mfigs will be saved to output/train/edgeyolo_tiny_coco/figures, please wait for seconds and see\u001b[0m\n",
      "\u001b[32m2025-05-08 12:32:33.568\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36medgeyolo.utils.plot_fig\u001b[0m:\u001b[36mplot_all\u001b[0m:\u001b[36m138\u001b[0m - \u001b[31m\u001b[1mplot error: output/train/edgeyolo_tiny_coco/log.txt does not exist!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python plot.py --all -f output/train/edgeyolo_tiny_coco --save --format png "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:32:34.449132Z",
     "iopub.status.busy": "2025-05-08T12:32:34.448897Z",
     "iopub.status.idle": "2025-05-08T12:32:34.594100Z",
     "shell.execute_reply": "2025-05-08T12:32:34.593421Z",
     "shell.execute_reply.started": "2025-05-08T12:32:34.449110Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import argparse\n",
      "import os.path as osp\n",
      "\n",
      "from edgeyolo.utils.plot_fig import plot, plot_ap, plot_all\n",
      "\n",
      "import matplotlib\n",
      "matplotlib.use('Agg')\n",
      "\n",
      "DEFAULT_SIZE = (20, 9)\n",
      "DEFAULT_SUFFIX = [\"svg\"]\n",
      "\n",
      "\n",
      "def get_args():\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    parser.add_argument(\"-ap\", \"--ap\", action=\"store_true\")\n",
      "    parser.add_argument(\"-loss\", \"--loss\", action=\"store_true\")\n",
      "    parser.add_argument(\"-lr\", \"--lr\", action=\"store_true\")\n",
      "    parser.add_argument(\"-a\", \"--all\", action=\"store_true\")\n",
      "\n",
      "    parser.add_argument(\"-f\", \"--file\", type=str, required=True)\n",
      "\n",
      "    parser.add_argument(\"-s\", \"--save\", action=\"store_true\")\n",
      "    parser.add_argument(\"--format\", type=str, default=DEFAULT_SUFFIX, nargs=\"+\")\n",
      "    parser.add_argument(\"--no-show\", action=\"store_true\")\n",
      "    return parser.parse_args()\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    args = get_args()\n",
      "    if args.ap:\n",
      "        plot_ap(args.file, show=not args.no_show, save=args.save, suffix=args.format, figsize=DEFAULT_SIZE)\n",
      "    elif args.loss:\n",
      "        plot(args.file, plot_type=\"loss\", show=not args.no_show, save=args.save, suffix=args.format, figsize=DEFAULT_SIZE)\n",
      "    elif args.lr:\n",
      "        plot(args.file, plot_type=\"lr\", show=not args.no_show, save=args.save, suffix=args.format, figsize=DEFAULT_SIZE)\n",
      "    elif args.all:\n",
      "        if osp.isfile(args.file):\n",
      "            args.file = osp.dirname(args.file)\n",
      "        plot_all(args.file, show=not args.no_show, figsize=DEFAULT_SIZE, save=args.save, suffix=args.format)\n"
     ]
    }
   ],
   "source": [
    "!cat /kaggle/working/edgeyolo/plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export: ONNX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T11:20:58.799315Z",
     "iopub.status.busy": "2025-05-08T11:20:58.798742Z",
     "iopub.status.idle": "2025-05-08T11:21:03.808866Z",
     "shell.execute_reply": "2025-05-08T11:21:03.808189Z",
     "shell.execute_reply.started": "2025-05-08T11:20:58.799291Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1brEcFBMN1rjAfA2ausSMxVRgGarJcCld\n",
      "From (redirected): https://drive.google.com/uc?id=1brEcFBMN1rjAfA2ausSMxVRgGarJcCld&confirm=t&uuid=45a4dcc6-529e-45bb-b1d8-0496f48af79e\n",
      "To: /kaggle/working/edgeyolo/epoch_50.pth\n",
      "100%|██████████████████████████████████████| 47.1M/47.1M [00:00<00:00, 62.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "# custom onnx - https://drive.google.com/file/d/1brEcFBMN1rjAfA2ausSMxVRgGarJcCld/view?usp=sharing\n",
    "!gdown --id 1brEcFBMN1rjAfA2ausSMxVRgGarJcCld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:32:34.595341Z",
     "iopub.status.busy": "2025-05-08T12:32:34.595049Z",
     "iopub.status.idle": "2025-05-08T12:32:44.431450Z",
     "shell.execute_reply": "2025-05-08T12:32:44.430724Z",
     "shell.execute_reply.started": "2025-05-08T12:32:34.595309Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-08 12:32:39.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36medgeyolo.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mloading models from weight /kaggle/working/edgeyolo/output/train/edgeyolo_s_coco/best.pth\u001b[0m\n",
      "/kaggle/working/edgeyolo/edgeyolo/models/__init__.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.ckpt = torch.load(weights, map_location=\"cpu\")\n",
      "Reparameterizing models...\n",
      "\u001b[32m2025-05-08 12:32:43.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36medgeyolo.export.pth2trt\u001b[0m:\u001b[36mtorch2onnx2trt\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1monnx file saved to output/export/best/640x640_batch1.onnx\u001b[0m\n",
      "\u001b[32m2025-05-08 12:32:43.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1mAll files are saved in output/export/best.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python export.py --onnx --weights /kaggle/working/edgeyolo/output/train/edgeyolo_s_coco/best.pth --input-size 640 640 --batch 1 --opset 11 --no-simplify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:32:44.434485Z",
     "iopub.status.busy": "2025-05-08T12:32:44.434267Z",
     "iopub.status.idle": "2025-05-08T12:32:44.439871Z",
     "shell.execute_reply": "2025-05-08T12:32:44.439342Z",
     "shell.execute_reply.started": "2025-05-08T12:32:44.434466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "available_gpus = list(range(torch.cuda.device_count()))\n",
    "print(f\"Available GPUs: {available_gpus}\")\n",
    "device = available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T12:38:10.205363Z",
     "iopub.status.busy": "2025-05-08T12:38:10.204859Z",
     "iopub.status.idle": "2025-05-08T12:38:10.813200Z",
     "shell.execute_reply": "2025-05-08T12:38:10.812518Z",
     "shell.execute_reply.started": "2025-05-08T12:38:10.205337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model is valid.\n",
      "Inference result: [array([[[8.77798939e+00, 7.26758480e+00, 1.21391808e+02, ...,\n",
      "         6.55770302e-03, 2.33633965e-01, 1.10857815e-01],\n",
      "        [1.39679241e+01, 7.72220039e+00, 3.02407593e+02, ...,\n",
      "         5.88473678e-03, 2.11204499e-01, 1.32242709e-01],\n",
      "        [2.07673416e+01, 6.57302999e+00, 3.60972595e+02, ...,\n",
      "         9.44903493e-03, 2.27701098e-01, 1.65245295e-01],\n",
      "        ...,\n",
      "        [5.50486206e+02, 6.30599243e+02, 1.52092285e+02, ...,\n",
      "         6.50972128e-04, 2.74412215e-01, 1.19058251e-01],\n",
      "        [5.82597656e+02, 6.31481812e+02, 1.33106110e+02, ...,\n",
      "         3.17066908e-04, 2.73171961e-01, 1.00513875e-01],\n",
      "        [6.12542114e+02, 6.26324097e+02, 8.09355316e+01, ...,\n",
      "         7.46518373e-04, 2.75898874e-01, 7.31824636e-02]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "onnx_model_path = \"/kaggle/working/edgeyolo/output/export/best/640x640_batch1.onnx\"\n",
    "\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"ONNX model is valid.\")\n",
    "\n",
    "session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "dummy_input = np.random.random_sample(session.get_inputs()[0].shape).astype(np.float32)\n",
    "\n",
    "result = session.run([output_name], {input_name: dummy_input})\n",
    "\n",
    "print(\"Inference result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T11:23:03.790489Z",
     "iopub.status.busy": "2025-05-08T11:23:03.790207Z",
     "iopub.status.idle": "2025-05-08T11:23:03.822306Z",
     "shell.execute_reply": "2025-05-08T11:23:03.821642Z",
     "shell.execute_reply.started": "2025-05-08T11:23:03.790469Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "output = result[0]\n",
    "confidence_threshold = 0.1\n",
    "\n",
    "for i in range(output.shape[0]):\n",
    "    detections = output[i]\n",
    "    for detection in detections:\n",
    "        confidence = detection[4]\n",
    "        if confidence > confidence_threshold:\n",
    "            x_center, y_center, width, height = detection[:4]\n",
    "            print(\n",
    "                f\"confidence {confidence} coordinates ({x_center}, {y_center}), \"\n",
    "                f\"Width: {width}, Height: {height}\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
